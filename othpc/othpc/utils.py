#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Copyright (C) EDF 2025

@authors: otwrapy
"""
from datetime import datetime
from tempfile import mkdtemp
import pandas as pd
import shutil
import os
import openturns as ot
import time 
import math
import logging


class TempSimuDir(object):
    """
    Implement a context manager that creates a temporary working directory.

    Create a temporary working directory on `res_dir` preceded by
    `prefix` and clean up at the exit if necessary.

    Parameters
    ----------
    res_dir : str
        Path where the temporary working directory will be created.
    prefix : str (optional)
        String that preceeds the directory name.
    cleanup : bool (optional)
        If True erase the directory and its children at the exit.
    to_be_copied : list (optional)
        List of files or folders to transfer to the temporary working directory
    """

    def __init__(self, res_dir, prefix="simu_", cleanup=False, to_be_copied=None):
        date_tag = datetime.now().strftime("%Y-%m-%d_%H-%M_")
        self.simu_dir = mkdtemp(dir=res_dir, prefix=prefix + date_tag)
        self.cleanup = cleanup
        self.to_be_copied = to_be_copied

    def __enter__(self):
        if self.to_be_copied is not None:
            for file in self.to_be_copied:
                if os.path.isfile(file):
                    shutil.copy(file, self.simu_dir)
                elif os.path.isdir(file):
                    shutil.copytree(
                        file, os.path.join(self.simu_dir, file.split(os.sep)[-1])
                    )
                else:
                    raise Exception(
                        "In othpc.TempSimuDir : the current "
                        + 'path "{}" is not a file '.format(file)
                        + "nor a directory to transfer."
                    )
        return self.simu_dir

    def __exit__(self, type, value, traceback):
        if self.cleanup:
            shutil.rmtree(self.simu_dir)


def make_report_file(
    simu_dir,
    x,
    y=None,
    report_file="report.csv",
    input_description=None,
    output_description=None,
):
    """
    Writes a report file associated to one evaluation, including the input and the corresponding output.

    Parameters
    ----------
    simu_dir : string
        Path where the inputs and outputs files associated to one evaluation are stored.
    x : list
        Input vector evaluated.
    y : list
        Corresponding output vector.
    report_file : string
        Name of the output file written.
    input_description : list
        List of strings describing the intputs.
    output_description :
        List of strings describing the outputs.
    """
    if input_description is None:
        input_description = [f"X{i}" for i in range(len(x))]
    else:
        input_description = list(input_description)
    if y is None:
        df = pd.DataFrame([], columns=input_description, index=[simu_dir])
    else:
        if output_description is None:
            output_description = [f"Y{i}" for i in range(len(y))]
        else:
            output_description = list(output_description)
        df = pd.DataFrame(
            [], columns=input_description + output_description, index=[simu_dir]
        )
    df.loc[simu_dir, input_description] = x
    if y is not None:
        df.loc[simu_dir, output_description] = y
    df.to_csv(os.path.join(simu_dir, report_file), na_rep="NaN")


def make_summary_file(res_dir, summary_file="summary.csv", report_file="report.csv"):
    """
    Writes a file including a summary table with all the inputs evaluated and their coressponding outputs.

    Parameters
    ----------
    res_dir : string
        Path where the temporary work files have beend created.
    summary_file : string
        Name of the summary file created.
    report_file : string
        Name of the files generated by the static method make_report_file.
    """
    df_table = pd.DataFrame([])
    subfolders = [f.path for f in os.scandir(res_dir) if f.is_dir()]
    for simu_dir in subfolders:
        try:
            df = pd.read_csv(
                os.path.join(simu_dir, report_file), index_col=0, na_values=["NaN", ""]
            )
            df_table = pd.concat([df_table, df])
        except FileNotFoundError:
            pass
    df_table.to_csv(os.path.join(res_dir, summary_file), na_rep="NaN")


def load_cache(function, summary_file):
    """
    Makes an ot.MemoizeFunction including in its cache the previous evaluations written in the summary_file

    Parameters
    ----------
    function : ot.Function
        Function that will be turned into a ot.MemoizeFunction
    summary_file : string
        Path to the summary file created by the make_summary_file method.
    """
    memoize_function = ot.MemoizeFunction(function)
    # load the cache from the summary file
    df = pd.read_csv(summary_file)
    df = df.drop(columns=df.columns[0])
    input_cache = ot.Sample.BuildFromDataFrame(
        df.iloc[:, : function.getInputDimension()]
    )
    output_cache = ot.Sample.BuildFromDataFrame(
        df.iloc[:, function.getInputDimension() :]
    )
    # add the cache to the function
    memoize_function.addCacheContent(input_cache, output_cache)
    return memoize_function


def evaluation_error_log(error, simulation_directory, name="evaluation_error.txt"):
    logger = logging.getLogger(__name__)
    logfile = os.path.join(simulation_directory, name)
    fh = logging.FileHandler(filename=logfile, mode='w')

    # Create a formatter for the file handlers
    formatter = logging.Formatter(
        fmt='%(asctime)s %(levelname)-8s %(message)s',
        datefmt='%y-%m-%d %H:%M:%S')
    fh.setFormatter(formatter)

    # Add the handler to the logger
    logger.addHandler(fh)
    logger.error(error)


def fake_load(duration=30):
    start = time.time()
    while time.time() - start < duration:
        a = math.sqrt(64 * 64 * 64 * 64 * 64)

# class MemoizeWithSave(ot.MemoizeFunction):
#     """
#     It provides additionnal methods to save and load cache input and output to the OT Function

#     Class that inherits from openturns.MemoizeFunction

#     Parameters
#     ----------
#     function : :class:`~openturns.Function`
#         The function in which the cache is loaded or saved.
#     cache_filename : str
#         Path to the cache filename, it must be a csv file.
#     logger_name : str
#         Name of the logger to use, default is None which is the root logger.
#     """

#     def __init__(self, function, cache_filename, logger_name=None):
#         self.cache_filename = cache_filename
#         self.logger = logging.getLogger(logger_name)
#         # transfer parameters of the original wrapper function
#         self.__dict__.update(function.__dict__)

#         super().__init__(function)

#     def save_cache(self, logging=True):
#         """
#         Save the input and output cache to a csv file.
#         """

#         # get the cache sample
#         cache_data = self.getCacheInput()
#         cache_data.stack(self.getCacheOutput())
#         cache_data.setDescription(self.getDescription())
#         cache_data.exportToCSVFile(self.cache_filename)

#         # internal flag to avoid repeated log message in FunctionAdvanced
#         if logging:
#             # print the number of saved evaluations
#             self.logger.info(
#                 f"Saved successfully {cache_data.getSize()} evaluations in "
#                 f'"{self.cache_filename}".'
#             )

#     def load_cache(self):
#         """
#         Load a csv file and add it to the cache of the function
#         """

#         # retreive the number of input
#         n_input = self.getInputDimension()

#         if os.path.isfile(self.cache_filename):
#             # load the cache from the file
#             cache_data = ot.Sample.ImportFromCSVFile(self.cache_filename)
#             # add the cache to the function
#             input_sample = cache_data[:, :n_input]
#             output_sample = cache_data[:, n_input:]
#             self.addCacheContent(input_sample, output_sample)

#             # print the number of loaded evaluations
#             self.logger.info(
#                 f"Loaded successfully {cache_data.getSize()} evaluations from "
#                 f"{self.cache_filename}."
#             )
#         else:
#             self.logger.info(
#                 f'Cache filename "{self.cache_filename}" not found. '
#                 "No evaluations loaded !"
#             )


# def explicit_error(cp):
#   if cp.returncode != 0:
#     print(''.join(['=']*20) + ' cmd ' + ''.join(['=']*20))
#     print(cmd)
#     print(''.join(['=']*20) + ' exit code ' + ''.join(['=']*20))
#     print(cp.returncode)
#     print(''.join(['=']*20) + ' stdout ' + ''.join(['=']*20))
#     print(cp.stdout.decode(platform_arg['encoding'][os.name]))
#     print(''.join(['=']*20) + ' stderr ' + ''.join(['=']*20))
#     print(cp.stderr.decode(platform_arg['encoding'][os.name]))
#     print(''.join(['=']*20) + '  ' + ''.join(['=']*20))
#     raise RuntimeError(cp.stderr.decode(platform_arg['encoding'][os.name]))
